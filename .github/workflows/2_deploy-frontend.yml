name: Deploy Frontend

on:
  workflow_dispatch:
  push:
    branches: [ master ]
    paths:
      - 'papers-feed/data/papers/gh-store-snapshot.json'
      - 'papers-feed/frontend/*'
      - '.github/workflows/2_deploy-frontend.yml'
  issues:
    types: [opened, closed, reopened]

concurrency:
  group: store-deploy
  cancel-in-progress: false

permissions:
  contents: write
  pages: write
  id-token: write
  actions: write  # Need write to trigger other workflows

jobs:
  update-snapshot:
    runs-on: ubuntu-latest
    outputs:
      changes_detected: ${{ steps.commit-changes.outputs.changes_detected }}
    steps:
      - name: Wait for updates (optional)
        uses: actions/github-script@v7
        continue-on-error: true
        with:
          script: |
            // Only wait if triggered by an issue event and there are active updates
            if (context.eventName === 'issues') {
              const runs = await github.rest.actions.listWorkflowRuns({
                owner: context.repo.owner,
                repo: context.repo.repo,
                workflow_id: '1_update_and_enrich.yml',
              });
              
              const activeUpdates = runs.data.workflow_runs.filter(run => 
                (run.status === 'in_progress' || run.status === 'queued') &&
                run.created_at > new Date(Date.now() - 5 * 60 * 1000).toISOString() // Only recent runs
              );
              
              if (activeUpdates.length > 0) {
                console.log(`Waiting for ${activeUpdates.length} active updates to complete...`);
                let waited = 0;
                const maxWait = 120; // 2 minutes max
                while (waited < maxWait && activeUpdates.length > 0) {
                  await new Promise(r => setTimeout(r, 10000));
                  waited += 10;
                  
                  const currentRuns = await github.rest.actions.listWorkflowRuns({
                    owner: context.repo.owner,
                    repo: context.repo.repo,
                    workflow_id: '1_update_and_enrich.yml',
                  });
                  
                  const stillActive = currentRuns.data.workflow_runs.filter(run => 
                    (run.status === 'in_progress' || run.status === 'queued')
                  );
                  
                  if (stillActive.length === 0) break;
                }
              }
            }
            console.log("Proceeding with snapshot generation...");

      - uses: actions/checkout@v4
      
      - uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'
          
      - name: Install dependencies
        run: pip install gh-store

      - name: Create snapshot directory
        run: |
          mkdir -p papers-feed/data/papers
          
      - name: Create initial snapshot if needed
        env:
          SNAPSHOT_PATH: papers-feed/data/papers/gh-store-snapshot.json
        run: |
          python3 << 'EOF'
          import json
          from pathlib import Path
          from datetime import datetime, timedelta, timezone
          
          snapshot_path = Path("${{ env.SNAPSHOT_PATH }}")
          if not snapshot_path.exists():
              snapshot_path.parent.mkdir(parents=True, exist_ok=True)
              # Create snapshot with very old timestamp so it picks up all existing papers
              # Set to 1 year ago to ensure all existing issues are included
              # Use UTC timezone-aware datetime
              old_timestamp = (datetime.now(timezone.utc) - timedelta(days=365)).isoformat()
              snapshot_data = {
                  "objects": {},
                  "snapshot_time": old_timestamp
              }
              with open(snapshot_path, 'w') as f:
                  json.dump(snapshot_data, f, indent=2)
              print(f"Created initial snapshot at {snapshot_path} with old timestamp to include all existing papers")
          else:
              # If snapshot exists but is empty or very new, reset timestamp to pick up all papers
              with open(snapshot_path) as f:
                  existing_data = json.load(f)
              objects_count = len(existing_data.get("objects", {}))
              paper_count = len([k for k in existing_data.get("objects", {}).keys() if k.startswith("paper:")])
              
              if paper_count == 0:
                  # Reset timestamp to very old to force full snapshot
                  # Use UTC timezone-aware datetime
                  old_timestamp = (datetime.now(timezone.utc) - timedelta(days=365)).isoformat()
                  existing_data["snapshot_time"] = old_timestamp
                  with open(snapshot_path, 'w') as f:
                      json.dump(existing_data, f, indent=2)
                  print(f"Reset snapshot timestamp to include all existing papers (was empty)")
              else:
                  print(f"Snapshot exists with {paper_count} papers, will update incrementally")
          EOF
          
      - name: Update snapshot from GitHub issues
        env:
          SNAPSHOT_PATH: papers-feed/data/papers/gh-store-snapshot.json
        run: |
          echo "Generating snapshot from GitHub issues..."
          python -m gh_store update-snapshot \
            --token ${{ secrets.GITHUB_TOKEN }} \
            --repo ${{ github.repository }} \
            --snapshot-path ${{ env.SNAPSHOT_PATH }}
          
          # Verify snapshot was created with data
          echo "Verifying snapshot contents..."
          python3 << 'EOF'
          import json
          from pathlib import Path
          
          snapshot_path = Path("${{ env.SNAPSHOT_PATH }}")
          if snapshot_path.exists():
              with open(snapshot_path) as f:
                  data = json.load(f)
              objects_count = len(data.get("objects", {}))
              paper_count = len([k for k in data.get("objects", {}).keys() if k.startswith("paper:")])
              print(f"✓ Snapshot created: {objects_count} total objects, {paper_count} papers")
              if paper_count == 0:
                  print("⚠ WARNING: No papers found in snapshot!")
                  print("This might mean:")
                  print("  1. No issues with 'stored-object' label exist")
                  print("  2. Issues exist but don't have paper: prefix")
                  print("  3. Issues need to be processed first")
              else:
                  # Show first few paper keys
                  paper_keys = [k for k in data.get("objects", {}).keys() if k.startswith("paper:")][:5]
                  print(f"Sample paper keys: {paper_keys}")
          else:
              print("✗ ERROR: Snapshot file was not created!")
              exit(1)
          EOF
      
      # - name: Convert data
      #   run: |
      #     python frontend/scripts/convert_store.py \
      #       --snapshot_path data/papers/gh-store-snapshot.json \
      #       --output_path data/papers/papers.json \
      #       --archive_path data/papers/papers-archive.json \
      #       --features_base data/papers

      - name: Upload papers data
        uses: actions/upload-artifact@v4
        with:
          name: papers-json
          path: papers-feed/data/papers/gh-store-snapshot.json

      - name: Commit changes
        id: commit-changes
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "chore: Update store snapshot [${{ github.run_id }}]"
          file_pattern: 'papers-feed/data/papers/**'
          skip_dirty_check: true
      
      - name: Trigger Jekyll rebuild
        if: steps.commit-changes.outputs.changes_detected == 'true'
        uses: actions/github-script@v7
        with:
          script: |
            // Trigger Jekyll workflow after snapshot is committed
            // Wait a moment for the commit to be available
            await new Promise(r => setTimeout(r, 2000));
            
            try {
              await github.rest.actions.createWorkflowDispatch({
                owner: context.repo.owner,
                repo: context.repo.repo,
                workflow_id: 'jekyll.yml',
                ref: 'master'
              });
              console.log('✅ Triggered Jekyll workflow to rebuild site with new snapshot');
            } catch (error) {
              console.log('⚠️ Could not trigger Jekyll workflow directly, but push event should trigger it');
              console.log('Error:', error.message);
            }
      
  deploy:
    needs: update-snapshot
    # Always deploy if manually triggered, or if snapshot was updated
    if: always() && (github.event_name == 'workflow_dispatch' || needs.update-snapshot.outputs.changes_detected == 'true' || needs.update-snapshot.result == 'success')
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: true

      - name: Download papers.json
        uses: actions/download-artifact@v4
        with:
          name: papers-json
          path: web/papers-feed/data/papers/

      - name: Build web directory
        run: |
          mkdir -p web/papers-feed/data/papers
          cp papers-feed/frontend/* web/papers-feed/
          
          # Copy snapshot data from artifact (downloaded earlier)
          if [ -f "web/papers-feed/data/papers/gh-store-snapshot.json" ]; then
            echo "Using snapshot from artifact"
            ls -lh web/papers-feed/data/papers/gh-store-snapshot.json
          elif [ -f "papers-feed/data/papers/gh-store-snapshot.json" ]; then
            echo "Copying snapshot from repository"
            cp papers-feed/data/papers/gh-store-snapshot.json web/papers-feed/data/papers/
            ls -lh web/papers-feed/data/papers/gh-store-snapshot.json
          else
            echo "Warning: No snapshot file found, creating empty one"
            echo '{"objects": {}, "snapshot_time": "'$(date -u +"%Y-%m-%dT%H:%M:%S")'"}' > web/papers-feed/data/papers/gh-store-snapshot.json
          fi
          
          # Verify snapshot has data (non-fatal warning)
          echo "Checking snapshot contents..."
          python3 << 'EOF'
          import json
          from pathlib import Path
          
          snapshot_path = Path("web/papers-feed/data/papers/gh-store-snapshot.json")
          if snapshot_path.exists():
              with open(snapshot_path) as f:
                  data = json.load(f)
              objects_count = len(data.get("objects", {}))
              paper_count = len([k for k in data.get("objects", {}).keys() if k.startswith("paper:")])
              print(f"Snapshot contains {objects_count} total objects, {paper_count} papers")
              if paper_count == 0:
                  print("⚠ WARNING: No papers found in snapshot! Feed will show empty state.")
              else:
                  print(f"✓ Successfully loaded {paper_count} papers")
          else:
              print("⚠ WARNING: Snapshot file not found! Creating empty one.")
          EOF
          
          # Copy paper features maintaining directory structure (if they exist)
          if [ -d "papers-feed/data/papers" ]; then
            find papers-feed/data/papers -type f -name "*.md" -path "*/features/*" -exec sh -c 'mkdir -p web/papers-feed/data/$(dirname "{}" | sed "s|papers-feed/data/||") && cp "{}" web/papers-feed/data/$(echo "{}" | sed "s|papers-feed/data/||")' \;
          fi

      - name: Get git info
        id: git-info
        run: |
          echo "branch=${GITHUB_REF#refs/heads/}" >> $GITHUB_OUTPUT
          echo "commit=$(git rev-parse --short HEAD)" >> $GITHUB_OUTPUT
          echo "repo=${GITHUB_REPOSITORY}" >> $GITHUB_OUTPUT

      - name: Create git info JSON
        run: |
          mkdir -p web/papers-feed/data
          echo "{\"branch\": \"${{ steps.git-info.outputs.branch }}\", \"commit\": \"${{ steps.git-info.outputs.commit }}\", \"repo\": \"${{ steps.git-info.outputs.repo }}\"}" > web/papers-feed/data/git-info.json

      - name: Deploy to GitHub Pages
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./web
          force_orphan: false
          keep_files: true
